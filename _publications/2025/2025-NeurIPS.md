---
title:          "Probabilistic Token Alignment for Large Language Model Fusion"
date:           2025-09-18 12:01:00 +0800
selected:       true
pub:            "Conference on Neural Information Processing Systems"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       ' <span class="badge badge-pill badge-publication badge-success">NeurIPS</span>'
pub_date:       "2025"

abstract: >-
  We introduce Probabilistic Token Alignment (PTA) for large language model fusion, reformulating token alignment as an optimal transport problem. PTA enhances performance and generality through distribution-aware learning while offering interpretability from a distributional perspective, which provides deeper insights into token alignment.
cover:          assets/images/paper/ptallm.jpg
authors:
  - Runjia Zeng
  - James Chenhao Liang
  - Cheng Han
  - Zhiwen Cao
  - Jiahao Liu
  - Xiaojun Quan
  - Yingjie Victor Chen
  - Lifu Huang
  - Tong Geng
  - Qifan Wang
  - Dongfang Liu
links:
  HomepageðŸ’»: https://runjia.tech/neurips_pta-llm/
  CodeðŸ’¾: https://github.com/runtsang/PTA-LLM
  PaperðŸ“‘: https://arxiv.org/abs/2509.17276
---
